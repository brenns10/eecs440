\documentclass[fleqn]{homework}

\student{Stephen Brennan (smb196)}
\course{EECS 440}
\assignment{Written 8}
\duedate{November 3, 2015}

\usepackage{mathtools}
%\usepackage{graphicx}

\begin{document}
  \maketitle

  \begin{problem}{1}
    \begin{question}
      Consider a modified SVM formulation derived using the plus-plane at
      $\vec{w}\cdot\vec{x} + b = c_1$ and the minus-plane at
      $\vec{w}\cdot\vec{x}+b=c_2$, $c_1>0$, $c_2<0$, $c_1 \ne -c_2$.  Explain
      the relationship between the decision surface obtained in this case and
      the decision surface obtained when $c_1 = -c_2$.  When would we prefer one
      over the other? (10 points.)
    \end{question}

    When you modify the constants $c_1$ and $c_2$ that define the plus and minus
    planes, in theory this should not modify the locations of the trained plus
    and minus plane.  Instead, it should just change the choices of $\vec{w}$
    and $b$ so that the same plus and minus planes are chosen.  When
    $c_1 = c_2$, this means that the resulting decision surface
    ($\vec{w}\cdot\vec{x} = 0$), is halfway between plus and minus plane.  When
    $c_1 \ne c_2$, the decision surface is somewhere not halfway between the
    plus and minus plane.  When $c_1 > -c_2$, the decision surface is translated
    closer to the minus plane, and when $-c_2 > c_1$, the decision surface is
    translated closer to the plus plane.

    You may prefer a decision surface translated more to the direction of a
    particular plane if you have some knowledge about the distribution of your
    training data.  For instance, if you have many more positive examples than
    negative examples, you are likely to have more outliers in your positive
    data, which may ``push'' your plus-plane more than the negative examples
    ``push'' your minus-plane.  In this situation, it may be desirable to have
    the final decision surface closer to the plus-plane to make the classifier
    generalizable to a balanced input set.
  \end{problem}

  \begin{problem}{2}
    \begin{question}
      For a constrained programming problem $\min_w f(w)$, s.t. $g_i(w) \le 0$,
      $h_j(w) = 0$, the generalized Lagrangian is defined by
      $\ell(w, \alpha, \beta) = f(w) + \sum a_i g_i(w) + \sum \beta_j h_j(w)$,
      $\alpha_i \ge 0$.  A primal linear program is a constrained program of the
      form: $\min_x c^Tx$ s.t. $Ax \ge b, x \ge 0$.  Using the generalized
      Lagrangian, show that the \textit{dual form} of the primal LP is
      $\max_u b^T u$, s.t. $A^T u \le c$, $u \ge 0$. (10 points)
    \end{question}

    We can write the constraints of the linear program as $g_i(\vec{x}) \le 0$,
    where $g_i(\vec{x}) = - \vec{a_i} \cdot \vec{x} + b_i$.  Here, $\vec{a_i}$
    stands for row $i$ of the matrix $A$ (as a vector).

    The Lagrangian for the linear programming problem is:

    \begin{align*}
      \ell(\vec{x}, \vec{\alpha})
      &= f(x) + \sum_i \alpha_i g_i(x) \\
      &= c^T \vec{x} + \sum_i \alpha_i (-\vec{a_i} \cdot \vec{x} + b_i) \\
      &= c^T \vec{x} - \sum_i \alpha_i \vec{a_i} \cdot \vec{x} + \sum_i \alpha_i b_i \\
      &= c^T \vec{x} - \sum_i \alpha_i \vec{a_i} \cdot \vec{x} + \alpha^T \cdot \vec{b} \\
    \end{align*}

    Applying the KKT condition that the gradient of the Lagrangian at the
    solution is zero:

    \begin{align*}
      \nabla_{\vec{x}}\ell(\vec{x}, \vec{\alpha})
      = c^T - \sum_i \alpha_i \vec{a_i} &= 0 \\
      c^T &= \sum_i \alpha_i \vec{a_i}
    \end{align*}

    Now, we substitute into the Lagrangian to find the objective function of the
    dual:

    \begin{align*}
      D(\vec{\alpha}) &= \left(\sum_i \alpha_i \vec{a_i}\right)\vec{x} - \sum_i \alpha_i \vec{a_i} \cdot \vec{x} + b^T \vec{\alpha} \\
      &= b^T \vec{\alpha} \\
    \end{align*}

    The dual form of the linear program is therefore $\max_\alpha b^T \alpha$.
    The constraint $\alpha \ge 0$ is a KKT condition.  I cannot find a
    justification for the constraint $A^T \alpha \le 0$ using the Generalized
    Lagrangian, although I know it to be true of the dual of linear programs in
    this form.
  \end{problem}

  \begin{problem}{3}
    \begin{question}
      Write down a linear program that, when solved, will yield a
      \textit{perceptron} that is as accurate as possible on an arbitrary
      training sample.  Explain your formulation.  Derive the dual form of the
      perceptron and write down an expression for the weights of the perceptron
      in terms of dot products between examples.  Use this form to propose an
      alternative perceptron learning algorithm different from the gradient
      descent procedure we derived in class.  Do you think your procedure will
      in fact produce the same solution as gradient descent? (15 points)
    \end{question}

    A perceptron should classify an example $\vec{x}$ positive if
    $\vec{w} \cdot \vec{x} - \sigma \ge 0$.  A perceptron that is as accurate as
    possible should minimize the number of errors, or misclassifications.  Using
    a method similar to SVMs, we can quantify the misclassifications using
    variables $\xi_i$.  The resulting program would be:

    \begin{align*}
      \min \sum_{i} \xi_i & \text{, s.t.} \\
      y_i(\vec{w}\cdot\vec{x}_i - \sigma) + \xi_i &\ge 0 \:\:\:\: \forall i\\
      \xi_i &\ge 0 \\
    \end{align*}

    It is worth noting that $\sigma$ may be set to one without losing any
    generalization ability, since $\vec{w}$ may be scaled to match any cutoff.
    So, the final linear program is:

    \begin{align*}
      \min \sum_{i} \xi_i & \text{, s.t.} \\
      y_i(\vec{w}\cdot\vec{x}_i - 1) + \xi_i &\ge 0 \:\:\:\: \forall i\\
      \xi_i &\ge 0 \\
    \end{align*}

    The constraints may be rewritten:
    $y_i \vec{w} \cdot \vec{x} + \xi_1 \ge y_i$.  The dual of this linear
    program (taken by a procedure learned in EECS 477, not the Generalized
    Lagrangian) is:

    \begin{align*}
      \max \sum y_i \alpha_i & \text{, s.t.} \\
      \alpha_i &\le 1 \:\:\:\: \forall i \\
      \sum_i \alpha_i x_{ij} y_i &= 0 \:\:\:\: \forall j \\
      \alpha_i &\ge 0 \\
    \end{align*}

    Here, $j$ corresponds to the indices of each feature (or weight).  There
    does not appear to be a closed form expression for the weights of the
    perceptron, even when applying the KKT conditions.  However, a reasonable
    learning algorithm would simply be to solve the primal linear program for
    weights.
  \end{problem}

  \begin{problem}{4}
    \begin{question}
      Derive the dual form corresponding to the primal SVM formulation for the
      linearly \textit{non}separable case (i.e. with the slack variables). (15
      points)
    \end{question}
  \end{problem}

\end{document}